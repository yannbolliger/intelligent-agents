\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{float}
\usepackage[top=0.8in, bottom=0.8in, left=0.8in, right=0.8in]{geometry}
\usepackage{graphicx}
\usepackage{wrapfig}
\graphicspath{ {./} }
% Add other packages here %


% put your group number and names in the author field
\title{\bf Exercise 2: A Reactive Agent for the Pickup and Delivery Problem}
\author{Group \textnumero: 90  Kyle Gerard, Yann Bolliger}

% the report should not be longer than 3 pages

\begin{document}
\maketitle

\section{Problem Representation}

\subsection{Representation Description}

We wanted our state to contain two types of information: the current city of the 
agent as well as the fact whether there is a task available in this city. For 
the tasks, we also need to distinguish between the different destinations of the 
tasks. Therefore our state is modelled by a tuple from the set:
$$
\mathcal{S} = \{ (c_{current}, c_{destination}) | 
c_{current} \in \mathcal{C},  
c_{destination} \in (\mathcal{C} - \{ c_{current}\}) \cup \{\mathtt{null}\} }
 \}
$$
where $\mathcal{C}$ is the set of all cities. Note that $\mathtt{null}$ denotes 
the case where there is no task available in the current city.
The exclusion of $c_{current}$ in the second place encodes that there are no 
tasks with delivery city equal to the pickup city.

Our actions are either a \texttt{Pickup} for the given task or a move to a 
neighboring city given by the set:
$$
\mathcal{A} = \{ \mathtt{Pickup} \} \cup \{ \mathtt{Move}(c) | c \in \mathcal{C} \}
$$




\subsection{Implementation Details}
% describe the implementation details of the representations above and the implementation details of the reinforcement learning algorithm you implemented

\section{Results}
% in this section, you describe several results from the experiments with your reactive agent

\subsection{Experiment 1: Discount factor}
% the purpose of this experiment is to understand how the discount factor influences the result

\subsubsection{Setting}
% you describe how you perform the experiment (you also need to specify the configuration used for the experiment)

\subsubsection{Observations}
% you describe the experimental results and the conclusions you inferred from these results

\subsection{Experiment 2: Comparisons with dummy agents}
% you compare the results of your agent with two dummy agents: the random agent that was already given in the starter files and another dummy agent that you define and create. You should report the results from the simulations using the topologies given in the starter files and optionally, additional topologies that you create.

\subsubsection{Setting}
% you describe how you perform the experiment and you describe the dummy agent you created (you also need to specify the configuration used for the experiment)

\subsubsection{Observations}
% elaborate on the observed results

\vdots

\subsection{Experiment n}
% other experiments you would like to present

\subsubsection{Setting}

\subsubsection{Observations}

\end{document}