\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amssymb} 
\usepackage{textcomp}
\usepackage{float}
\usepackage[top=0.8in, bottom=0.8in, left=0.8in, right=0.8in]{geometry}
\usepackage{graphicx}
\usepackage{wrapfig}
\graphicspath{ {./} }
% Add other packages here %


% Put your group number and names in the author field %
\title{\bf Excercise 3\\ Implementing a deliberative Agent}
\author{Group \textnumero : 90  Kyle Gerard, Yann Bolliger}


% N.B.: The report should not be longer than 3 pages %


\begin{document}
\maketitle

\section{Model Description}

\subsection{Intermediate States}
Mathematically seen our state contains the position of the agent and all the not yet
delivered tasks. That means all the tasks the agent has already picked up
and all the tasks to be picked up yet. This could be written as the following state space:

$$
\mathcal{S} = \mathcal{C} 
\times
\{ A_{carried} : A_{carried} \subseteq \mathcal{T} \}
\times
\{ A_{pending} : A_{pending} \subseteq \mathcal{T} , 
  A_{pending}  \cap A_{carried}  = \emptyset
  \}
$$

where $\mathcal{C} $ is the set of cities and $ \mathcal{T}$ is the overall set 
of tasks. 

\subsection{Goal State}
A goal state is reached when all packets are delivered. Therefore it is 
defined as:

$$
\mathcal{S}_{goal} =  \{  (C, A_{carried}, A_{pending}) \in  \mathcal{S} : 
A_{carried} = \emptyset \wedge A_{pending} = \emptyset \} \subset  \mathcal{S}
$$

\subsection{Actions}
At each state there are up to three possible actions: move, pickup, deliver. 
They all have some conditions on the current state:

\begin{itemize}
  \item
  The agent can move only to neighbors of the current city encoded in the state. 
  This changes the city for the next state, the rest stays the same.
  
    \item
  The agent can deliver a task if $ \exists T \in A_{carried}$ which has 
  to be delivered at the current city of the agent.
  Then this task is removed from $A_{carried}$ for the next state.
  
  \item
  The agent can pickup a task only if $\exists T \in A_{pending} $ which has to 
  be picked up from the current city of the agent and if 
  $\sum_{T \in A_{carried} } \text{weight} (T) < $ maximal capacity of the 
  vehicle.
  In that case $T$ is removed from  $A_{pending}$  and added to $A_{carried}$ 
  for the next state.
\end{itemize}



\section{Implementation}

\subsection{BFS}
We closely followed the BFS algorithm. However, instead of stopping the 
search at the first goal node, we traverse the entire tree, collect all goal nodes and take the plan 
with the minimal among them.

There are some important keypoints to speed in this. 
We defined a specialised node class that acts as nodes in 
the search tree. These nodes don't only store the formal \texttt{State} of the 
agent but also the plan up to this state and the corresponding cost. This 
saves us from recomputing the two properties for each search node at each iteration. 
Another point is cylce detection. This is where we prevent reconsidering 
states we have already seen unless we find them with a smaller cost.

The most important speedup comes however from choosing the correct data structures.
For $\mathcal{O}(1)$ lookups of states in the cycle detection and other lookups we 
always use a \texttt{HashMap} together with the hash function of the class 
\texttt{State}.
For the search agenda queue we rather use a linked list in order to prevent costly 
array-copying. This makes our BFS reasonably fast for up to 11 tasks.

\subsection{A*}
As in BFS, we closely followed to algorithm given and made use of an admissible 
heuristic. This lets us do simpler cycle detection because we know that we find a 
state optimally in the first place. Again, we wrote a \texttt{Node} 
class that keeps track of the state, the plan, the cost and the heuristic in the 
search tree.

We also reused \texttt{HashMap} for cycle detection but here,
 we leveraged even more of Java's rich collection API. In fact, the search 
agenda queue is a \texttt{PriorityQueue}. This is a binary heap implementation 
and works with the \texttt{compareTo} method of \texttt{Node}. Therefore it automatically 
gives us the search node with the lowest $f()$ value in $\mathcal{O}(1)$ 
time (insertion is $\mathcal{O}(\log n)$). This is an immense advantage 
compared to sorting the entire 
list of search nodes in $\mathcal{O}(n \log n)$ time!

\subsection{Heuristic Function}
The heuristic in our A*-Algorithm must be admissible. It is defined for a state 
$S = (C, A_{carried}, A_{pending})$:

$$
h(S) = \max (h(A_{carried}), h(A_{pending})) 
$$$$
h(A_{carried}) = \max_{T \in A_{carried}} \text{distance}(C, \text{destination}(T))
$$$$
h(A_{pending}) = \max_{T \in A_{pending}} \text{distance}(C, \text{origin}(T)) + 
\text{distance}(\text{origin}(T), \text{destination}(T))
$$

This is admissible because if the agent has at least one pending task, it has \textit{at least}
to go to the task's origin, pick it up and deliver it. In that case the heuristic exactly 
calculates the cost. If the agent has more tasks, the heuristic will underestimate the cost. 
The same is true if the agent only has one carried task. Therefore the heuristic 
is admissible.

--> monotonic, optimal?


\section{Results}

\subsection{Experiment 1: BFS and A* Comparison}
% Compare the two algorithms in terms of: optimality, efficiency, limitations %
% Report the number of tasks for which you can build a plan in less than one minute %

\subsubsection{Setting}
% Describe the settings of your experiment: topology, task configuration, etc. %
The configuration file used was the one given in the handout called 
\texttt{deliberative.xml} with \texttt{rngSeed} left as is at 23456. 
Both the BFS and ASTAR algorithms were used. For each algorithm, 
we measured the time to compute the optimal plan as a function of the 
number of tasks to pickup and deliver.  

\subsubsection{Observations}
% Describe the experimental results and the conclusions you inferred from these results %
\begin{center}
\includegraphics[width=12cm]{time.png}
\end{center}
As seen in the graph above, both the ASTAR and BFS algorithms' time to compute the 
optimal plan grows exponentially in the number of tasks to deliver. 
We also remark that the ASTAR algorithm runs significantly faster than BFS. 
Using BFS we can build a plan with 11 tasks in 38 seconds. 
Using ASTAR we can build a plan with 13 tasks in 15 seconds. 
Therefore, even though both algorithms compute the optimal plan, 
ASTAR is more efficient than BFS. However as both algorithm's complexity 
is exponential, both algorithms are of limited use (much too slow) 
as the number of tasks keeps increasing.

\subsection{Experiment 2: Multi-agent Experiments}
% Observations in multi-agent experiments %

\subsubsection{Setting}
% Describe the settings of your experiment: topology, task configuration, etc. %
Here we use the ASTAR algorithm for all agents because it is faster than 
BFS. Still using the given \texttt{deliberative.xml} configuration file, 
we examine the behavior of the agents depending on the number of agents in the environment.

\subsubsection{Observations}
% Describe the experimental results and the conclusions you inferred from these results %
\begin{center}
\includegraphics[width=6cm]{follow.png}
\end{center}
With more than one agent in the environment we rapidly observe that the 
agents no longer act optimally. Indeed, their "optimal" plans computed by 
the ASTAR algorithm do not take into account the other agents' plans. 
This means that the agents will travel to a city to pickup a task even though 
another agent is closer to the city and thus will pickup the task first. 
In the figure above we see three agents going to the same pickup city even 
though there is only one task to be picked up. 
In this case the optimal plan would be to not try and pickup a task from a city 
when another agent will reach it earlier. 
\end{document}
